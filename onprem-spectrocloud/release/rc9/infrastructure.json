{
  "metadata": {
    "name": "_ddp_prefix-ddp-vmware-infra",
    "description": "",
    "labels": {
      "owner": "ddp"
    }
  },
  "spec": {
    "version": "1.0.0-rc9",
    "template": {
      "type": "cluster",
      "cloudType": "vsphere",
      "packs": [
        {
          "name": "ubuntu-vsphere",
          "type": "spectro",
          "layer": "os",
          "version": "20.04",
          "tag": "LTS__20.4.x",
          "values": "kubeadmconfig:\n  preKubeadmCommands:\n  - 'echo {{.spectro.macro._ddp_prefix-base64encode_acr_creds}} | base64 -d >> /etc/containerd/config.toml'\n  - 'systemctl restart containerd; sleep 3'",
          "registry": {
            "metadata": {
              "uid": "",
              "name": "Public Repo",
              "kind": "pack",
              "isPrivate": false
            }
          }
        },
        {
          "name": "kubernetes",
          "type": "spectro",
          "layer": "k8s",
          "version": "1.24.10",
          "tag": "1.24.x",
          "values": "# spectrocloud.com/enabled-presets: Kube Controller Manager:loopback-ctrlmgr,Kube Scheduler:loopback-scheduler\npack:\n  k8sHardening: True\n  #CIDR Range for Pods in cluster\n  # Note : This must not overlap with any of the host or service network\n  podCIDR: \"{{.spectro.macro._ddp_prefix-podCIDR}}\"\n  #CIDR notation IP range from which to assign service cluster IPs\n  # Note : This must not overlap with any IP ranges assigned to nodes for pods.\n  serviceClusterIpRange: \"{{.spectro.macro._ddp_prefix-serviceClusterIpRange}}\"\n\n# KubeAdm customization for kubernetes hardening. Below config will be ignored if k8sHardening property above is disabled\nkubeadmconfig:\n  apiServer:\n    extraArgs:\n      # Note : secure-port flag is used during kubeadm init. Do not change this flag on a running cluster\n      secure-port: \"6443\"\n      anonymous-auth: \"true\"\n      profiling: \"false\"\n      disable-admission-plugins: \"AlwaysAdmit\"\n      default-not-ready-toleration-seconds: \"60\"\n      default-unreachable-toleration-seconds: \"60\"\n      enable-admission-plugins: \"AlwaysPullImages,NamespaceLifecycle,ServiceAccount,NodeRestriction,PodSecurityPolicy\"\n      audit-log-path: /var/log/apiserver/audit.log\n      audit-policy-file: /etc/kubernetes/audit-policy.yaml\n      audit-log-maxage: \"30\"\n      audit-log-maxbackup: \"10\"\n      audit-log-maxsize: \"100\"\n      authorization-mode: RBAC,Node\n      tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n    extraVolumes:\n      - name: audit-log\n        hostPath: /var/log/apiserver\n        mountPath: /var/log/apiserver\n        pathType: DirectoryOrCreate\n      - name: audit-policy\n        hostPath: /etc/kubernetes/audit-policy.yaml\n        mountPath: /etc/kubernetes/audit-policy.yaml\n        readOnly: true\n        pathType: File\n  controllerManager:\n    extraArgs:\n      profiling: \"false\"\n      terminated-pod-gc-threshold: \"25\"\n      pod-eviction-timeout: \"1m0s\"\n      use-service-account-credentials: \"true\"\n      feature-gates: \"RotateKubeletServerCertificate=true\"\n  scheduler:\n    extraArgs:\n      profiling: \"false\"\n  kubeletExtraArgs:\n    read-only-port : \"0\"\n    event-qps: \"0\"\n    feature-gates: \"RotateKubeletServerCertificate=true\"\n    protect-kernel-defaults: \"true\"\n    tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n  files:\n    - path: hardening/audit-policy.yaml\n      targetPath: /etc/kubernetes/audit-policy.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/privileged-psp.yaml\n      targetPath: /etc/kubernetes/hardening/privileged-psp.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/90-kubelet.conf\n      targetPath: /etc/sysctl.d/90-kubelet.conf\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n  preKubeadmCommands:\n    # For enabling 'protect-kernel-defaults' flag to kubelet, kernel parameters changes are required\n    - 'echo \"====> Applying kernel parameters for Kubelet\"'\n    - 'sysctl -p /etc/sysctl.d/90-kubelet.conf'\n  postKubeadmCommands:\n    # Apply the privileged PodSecurityPolicy on the first master node ; Otherwise, CNI (and other) pods won't come up\n    # Sometimes api server takes a little longer to respond. Retry if applying the pod-security-policy manifest fails\n    - 'export KUBECONFIG=/etc/kubernetes/admin.conf && [ -f \"$KUBECONFIG\" ] && { echo \" ====> Applying PodSecurityPolicy\" ; until $(kubectl apply -f /etc/kubernetes/hardening/privileged-psp.yaml > /dev/null ); do echo \"Failed to apply PodSecurityPolicies, will retry in 5s\" ; sleep 5 ; done ; } || echo \"Skipping PodSecurityPolicy for worker nodes\"'\n\n# Client configuration to add OIDC based authentication flags in kubeconfig\n#clientConfig:\n  #oidc-issuer-url: \"{{ .spectro.pack.kubernetes.kubeadmconfig.apiServer.extraArgs.oidc-issuer-url }}\"\n  #oidc-client-id: \"{{ .spectro.pack.kubernetes.kubeadmconfig.apiServer.extraArgs.oidc-client-id }}\"\n  #oidc-client-secret: 1gsranjjmdgahm10j8r6m47ejokm9kafvcbhi3d48jlc3rfpprhv\n  #oidc-extra-scope: profile,email",
          "registry": {
            "metadata": {
              "uid": "",
              "name": "Public Repo",
              "kind": "pack",
              "isPrivate": false
            }
          }
        },
        {
          "name": "cni-calico",
          "type": "spectro",
          "layer": "cni",
          "version": "3.24.5",
          "tag": "3.24.x",
          "values": "pack:\n  content:\n    images:\n      - image: gcr.io/spectro-images-public/calico/cni:v3.24.5\n      - image: gcr.io/spectro-images-public/calico/node:v3.24.5\n      - image: gcr.io/spectro-images-public/calico/kube-controllers:v3.24.5\n\nmanifests:\n  calico:\n\n    # IPAM type to use. Supported types are calico-ipam, host-local\n    ipamType: \"calico-ipam\"\n\n    # Should be one of CALICO_IPV4POOL_IPIP or CALICO_IPV4POOL_VXLAN  \n    encapsulationType: \"CALICO_IPV4POOL_IPIP\"\n\n    # Should be one of Always, CrossSubnet, Never\n    encapsulationMode: \"Always\"\n\n    env:\n      # Additional env variables for calico-node\n      calicoNode:\n        #CALICO_IPV4POOL_CIDR: \"192.168.0.0/16\"\n        #IP_AUTODETECTION_METHOD: \"first-found\"\n\n      # Additional env variables for calico-kube-controller deployment\n      calicoKubeControllers:\n        #LOG_LEVEL: \"info\"\n        #SYNC_NODE_LABELS: \"true\"",
          "registry": {
            "metadata": {
              "uid": "",
              "name": "Public Repo",
              "kind": "pack",
              "isPrivate": false
            }
          }
        },
        {
          "name": "csi-vsphere-csi",
          "type": "spectro",
          "layer": "csi",
          "version": "2.6.0",
          "tag": "2.6.x",
          "values": "manifests:\n  #Storage class config\n  vsphere:\n\n    #Toggle for Default class\n    isDefaultClass: \"true\"\n\n    #Specifies file system type\n    fstype: \"ext4\"\n\n    #Allowed reclaim policies are Delete, Retain\n    reclaimPolicy: \"Delete\"\n\n    #Specifies the URL of the datastore on which the container volume needs to be provisioned.\n    datastoreURL: \"\"\n\n    #Specifies the storage policy for datastores on which the container volume needs to be provisioned.\n    storagePolicyName: \"\"\n\n    volumeBindingMode: \"WaitForFirstConsumer\"\n\n    #Set this flag to true to enable volume expansion\n    allowVolumeExpansion: true\n\n  vsphere-cloud-controller-manager:\n    k8sVersion: \"{{ .spectro.system.kubernetes.version }}\"\n\n  vsphere-csi-driver:\n    replicas: 3\n    extraArgs:\n      csiAttacher:\n        - \"--v=4\"\n        - \"--timeout=300s\"\n        - \"--csi-address=$(ADDRESS)\"\n        - \"--leader-election\"\n        - \"--kube-api-qps=100\"\n        - \"--kube-api-burst=100\"\n      csiResizer:\n        - \"--v=4\"\n        - \"--timeout=300s\"\n        - \"--handle-volume-inuse-error=false\"\n        - \"--csi-address=$(ADDRESS)\"\n        - \"--kube-api-qps=100\"\n        - \"--kube-api-burst=100\"\n        - \"--leader-election\"    \n      csiController:\n        - \"--fss-name=internal-feature-states.csi.vsphere.vmware.com\"\n        - \"--fss-namespace=$(CSI_NAMESPACE)\"\n      csiLivenessProbe:\n        - \"--v=4\"\n        - \"--csi-address=/csi/csi.sock\"      \n      csiSyncer:\n        - \"--leader-election\"\n        - \"--fss-name=internal-feature-states.csi.vsphere.vmware.com\"\n        - \"--fss-namespace=$(CSI_NAMESPACE)\"\n      csiProvisioner:\n        - \"--v=4\"\n        - \"--timeout=300s\"\n        - \"--csi-address=$(ADDRESS)\"\n        - \"--kube-api-qps=100\"\n        - \"--kube-api-burst=100\"\n        - \"--leader-election\"\n        - \"--default-fstype=ext4\"\n        # needed only for topology aware setup\n        - \"--feature-gates=Topology=true\"\n        - \"--strict-topology\"\n      csiSnapshotter:\n        - \"--v=4\"\n        - \"--kube-api-qps=100\"\n        - \"--kube-api-burst=100\"\n        - \"--timeout=300s\"\n        - \"--csi-address=$(ADDRESS)\"\n        - \"--leader-election\"",
          "registry": {
            "metadata": {
              "uid": "",
              "name": "Public Repo",
              "kind": "pack",
              "isPrivate": false
            }
          }
        }
      ]
    }
  }
}
